{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "# Plotting and dealing with images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Interactive widgets\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of base directory: ['test', 'train', 'val']\n",
      "\n",
      "Contents of train directory: C:\\Users\\toran\\Documents\\GitHub\\ML_PadiCare\\data\\train\n",
      "\n",
      "Contents of validation directory: C:\\Users\\toran\\Documents\\GitHub\\ML_PadiCare\\data\\val\n",
      "\n",
      "Contents of test directory: C:\\Users\\toran\\Documents\\GitHub\\ML_PadiCare\\data\\test\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = r'C:\\Users\\toran\\Documents\\GitHub\\ML_PadiCare\\data'\n",
    "\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "test_dir = os.path.join(BASE_DIR, 'test')\n",
    "validation_dir = os.path.join(BASE_DIR, 'val')\n",
    "# Directory with training \n",
    "train_leafblight_dir = os.path.join(train_dir, 'bacterial_leaf_blight')\n",
    "train_panicleblight_dir = os.path.join(train_dir, 'bacterial_panicle_blight')\n",
    "train_brownspot_dir = os.path.join(train_dir, 'brown_spot')\n",
    "train_sheathblight_dir = os.path.join(train_dir, 'rice_sheath_blight')\n",
    "train_normal_dir = os.path.join(train_dir, 'normal')\n",
    "# Directory with validation \n",
    "validation_leafblight_dir = os.path.join(validation_dir, 'bacterial_leaf_blight')\n",
    "validation_panicleblight_dir = os.path.join(validation_dir, 'bacterial_panicle_blight')\n",
    "validation_brownspot_dir = os.path.join(validation_dir, 'brown_spot')\n",
    "validation_sheathblight_dir = os.path.join(validation_dir, 'rice_sheath_blight')\n",
    "validation_normal_dir = os.path.join(validation_dir, 'normal')\n",
    "# Directory with test \n",
    "test_leafblight_dir = os.path.join(test_dir, 'bacterial_leaf_blight')\n",
    "test_panicleblight_dir = os.path.join(test_dir, 'bacterial_panicle_blight')\n",
    "test_brownspot_dir = os.path.join(test_dir, 'brown_spot')\n",
    "test_sheathblight_dir = os.path.join(test_dir, 'rice_sheath_blight')\n",
    "test_normal_dir = os.path.join(test_dir, 'normal')\n",
    "print(f\"Contents of base directory: {os.listdir(BASE_DIR)}\")\n",
    "print(f\"\\nContents of train directory: {train_dir}\")\n",
    "print(f\"\\nContents of validation directory: {validation_dir}\")\n",
    "print(f\"\\nContents of test directory: {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_leafblight_fnames = os.listdir(train_leafblight_dir)\n",
    "train_panicleblight_fnames = os.listdir(train_panicleblight_dir )\n",
    "train_brownspot_fnames = os.listdir(train_brownspot_dir)\n",
    "train_sheathblight_fnames = os.listdir(train_sheathblight_dir )\n",
    "train_normal_fnames = os.listdir(train_normal_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1423 images belonging to 5 classes.\n",
      "Found 604 images belonging to 5 classes.\n",
      "Found 757 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parameter augmentasi\n",
    "BATCH_SIZE = 20\n",
    "IMG_HEIGHT, IMG_WIDTH = 150, 150\n",
    "\n",
    "# Augmentasi data training\n",
    "image_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.50,\n",
    "    rotation_range=45,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15\n",
    ")\n",
    "\n",
    "train_data_gen = image_train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Normalisasi data validasi tanpa augmentasi\n",
    "img_val_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_data_gen = img_val_gen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Normalisasi data testing tanpa augmentasi\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = test_data_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(150, 150, 3)),\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropout\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18496</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18496</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,470,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18496\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18496\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m9,470,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m2,565\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,496,613</span> (36.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,496,613\u001b[0m (36.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,496,613</span> (36.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,496,613\u001b[0m (36.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1423 images belonging to 5 classes.\n",
      "Found 604 images belonging to 5 classes.\n",
      "Found 757 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parameter augmentasi\n",
    "BATCH_SIZE = 20\n",
    "IMG_HEIGHT, IMG_WIDTH = 150, 150\n",
    "\n",
    "# Augmentasi data training\n",
    "image_train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.50,\n",
    "    rotation_range=45,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15\n",
    ")\n",
    "\n",
    "train_data_gen = image_train_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Normalisasi data validasi tanpa augmentasi\n",
    "img_val_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_data_gen = img_val_gen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Normalisasi data testing tanpa augmentasi\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = test_data_gen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_final = train_dataset.cache().shuffle(SHUFFLE_BUFFER_SIZE).prefetch(PREFETCH_BUFFER_SIZE)\n",
    "validation_dataset_final = validation_dataset.cache().prefetch(PREFETCH_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Pastikan pipeline `train_dataset` menggunakan generator yang sesuai\n",
    "# Konversi ke array untuk menghitung class weights\n",
    "train_labels = np.concatenate([y for _, y in train_data_gen])  # Ambil label dari generator\n",
    "\n",
    "# Karena label dari `ImageDataGenerator` berbentuk kategori (class_mode='sparse'),\n",
    "# tidak perlu menggunakan np.argmax\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "# Konversi class_weights ke format dictionary yang diterima oleh Keras\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Gunakan class_weights saat training\n",
    "history = model.fit(\n",
    "    train_dataset_final,  # Pipeline dengan augmentasi\n",
    "    epochs=15,\n",
    "    validation_data=validation_dataset_final,\n",
    "    verbose=2,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "115/115 - 37s - 321ms/step - accuracy: 0.9798 - loss: 0.1337 - val_accuracy: 0.8946 - val_loss: 0.5063\n",
      "Epoch 2/15\n",
      "115/115 - 26s - 228ms/step - accuracy: 0.9820 - loss: 0.1120 - val_accuracy: 0.8986 - val_loss: 0.5606\n",
      "Epoch 3/15\n",
      "115/115 - 28s - 248ms/step - accuracy: 0.9811 - loss: 0.1065 - val_accuracy: 0.8933 - val_loss: 0.4517\n",
      "Epoch 4/15\n",
      "115/115 - 33s - 283ms/step - accuracy: 0.9939 - loss: 0.0727 - val_accuracy: 0.8906 - val_loss: 0.5936\n",
      "Epoch 5/15\n",
      "115/115 - 33s - 288ms/step - accuracy: 0.9855 - loss: 0.0956 - val_accuracy: 0.8986 - val_loss: 0.4890\n",
      "Epoch 6/15\n",
      "115/115 - 33s - 289ms/step - accuracy: 0.9860 - loss: 0.0927 - val_accuracy: 0.8986 - val_loss: 0.5548\n",
      "Epoch 7/15\n",
      "115/115 - 33s - 288ms/step - accuracy: 0.9851 - loss: 0.0868 - val_accuracy: 0.9012 - val_loss: 0.4714\n",
      "Epoch 8/15\n",
      "115/115 - 28s - 243ms/step - accuracy: 0.9899 - loss: 0.0784 - val_accuracy: 0.9038 - val_loss: 0.5552\n",
      "Epoch 9/15\n",
      "115/115 - 28s - 247ms/step - accuracy: 0.9899 - loss: 0.0829 - val_accuracy: 0.8722 - val_loss: 0.6946\n",
      "Epoch 10/15\n",
      "115/115 - 30s - 258ms/step - accuracy: 0.9855 - loss: 0.0843 - val_accuracy: 0.9078 - val_loss: 0.5629\n",
      "Epoch 11/15\n",
      "115/115 - 28s - 246ms/step - accuracy: 0.9864 - loss: 0.0916 - val_accuracy: 0.9091 - val_loss: 0.5045\n",
      "Epoch 12/15\n",
      "115/115 - 28s - 242ms/step - accuracy: 0.9912 - loss: 0.0609 - val_accuracy: 0.8867 - val_loss: 0.5025\n",
      "Epoch 13/15\n",
      "115/115 - 27s - 238ms/step - accuracy: 0.9947 - loss: 0.0568 - val_accuracy: 0.9051 - val_loss: 0.5163\n",
      "Epoch 14/15\n",
      "115/115 - 28s - 246ms/step - accuracy: 0.9899 - loss: 0.0702 - val_accuracy: 0.8643 - val_loss: 0.8430\n",
      "Epoch 15/15\n",
      "115/115 - 29s - 252ms/step - accuracy: 0.9868 - loss: 0.0717 - val_accuracy: 0.9091 - val_loss: 0.4367\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset_final,\n",
    "    epochs=15,\n",
    "    validation_data=validation_dataset_final,\n",
    "    verbose=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ebc7d5a3834c1caa714ff00f37f675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae14d92286df49deb043610661913fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definisikan widget FileUpload\n",
    "uploader = widgets.FileUpload(accept=\"image/*\", multiple=True)\n",
    "display(uploader)\n",
    "\n",
    "# Output widget untuk menampilkan hasil prediksi\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "# Fungsi untuk memproses dan memprediksi setiap file gambar\n",
    "def file_predict(filename, file, out):\n",
    "    \"\"\"Fungsi untuk membuat prediksi dan mencetak hasilnya.\"\"\"\n",
    "    # Load gambar, ubah ukuran, dan ubah ke array\n",
    "    image = tf.keras.utils.load_img(file, target_size=(150, 150))\n",
    "    image = tf.keras.utils.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = image / 255.0  # Normalisasi\n",
    "\n",
    "    # Prediksi menggunakan model\n",
    "    predictions = model.predict(image, verbose=0)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    # Mapping label kelas\n",
    "    class_names = [\n",
    "        \"Bacterial Leaf Blight\",\n",
    "        \"Bacterial Panicle Blight\",\n",
    "        \"Brown Spot\",\n",
    "        \"Rice Sheath Blight\",\n",
    "        \"Normal\"\n",
    "    ]\n",
    "    predicted_label = class_names[predicted_class]\n",
    "\n",
    "    # Tampilkan hasil prediksi\n",
    "    with out:\n",
    "        print(f\"{filename} -> {predicted_label}\")\n",
    "\n",
    "# Fungsi untuk menangani perubahan pada uploader\n",
    "def on_upload_change(change):\n",
    "    \"\"\"Fungsi untuk menangani file yang diunggah dan memproses prediksi.\"\"\"\n",
    "    # Bersihkan output sebelumnya\n",
    "    out.clear_output()\n",
    "\n",
    "    # Ambil file yang baru diunggah\n",
    "    items = change.new\n",
    "    for item in items:  # Loop jika ada lebih dari satu file\n",
    "        file_jpgdata = BytesIO(item.content)\n",
    "        file_predict(item.name, file_jpgdata, out)\n",
    "\n",
    "# Hubungkan fungsi observasi ke uploader\n",
    "uploader.observe(on_upload_change, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(150, 150, 3)),\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
