{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensrflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r'C:\\Users\\toran\\Documents\\GitHub\\ML_PadiCare\\data'\n",
    "train_dir = os.path.join(BASE_DIR, 'train')\n",
    "validation_dir = os.path.join(BASE_DIR, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 4 classes.\n",
      "Found 452 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_dataset = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(\n",
    "    weights='imagenet', include_top=False, input_shape=(150, 150, 3)\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toran\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 - 226s - 4s/step - accuracy: 0.3167 - loss: 2.1247 - val_accuracy: 0.2898 - val_loss: 1.6521 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "57/57 - 212s - 4s/step - accuracy: 0.4006 - loss: 1.8324 - val_accuracy: 0.2367 - val_loss: 1.9000 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "57/57 - 189s - 3s/step - accuracy: 0.4228 - loss: 1.6937 - val_accuracy: 0.2500 - val_loss: 3.7907 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "57/57 - 188s - 3s/step - accuracy: 0.4383 - loss: 1.6129 - val_accuracy: 0.2323 - val_loss: 3.0396 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "57/57 - 193s - 3s/step - accuracy: 0.4778 - loss: 1.4552 - val_accuracy: 0.2854 - val_loss: 3.5444 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "57/57 - 185s - 3s/step - accuracy: 0.4728 - loss: 1.4173 - val_accuracy: 0.2810 - val_loss: 3.5475 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "57/57 - 198s - 3s/step - accuracy: 0.4928 - loss: 1.3809 - val_accuracy: 0.2456 - val_loss: 2.6910 - learning_rate: 2.0000e-05\n",
      "Epoch 8/20\n",
      "57/57 - 189s - 3s/step - accuracy: 0.4772 - loss: 1.3694 - val_accuracy: 0.2810 - val_loss: 2.3779 - learning_rate: 2.0000e-05\n",
      "Epoch 9/20\n",
      "57/57 - 202s - 4s/step - accuracy: 0.5067 - loss: 1.3060 - val_accuracy: 0.2721 - val_loss: 2.4849 - learning_rate: 2.0000e-05\n",
      "Epoch 10/20\n",
      "57/57 - 185s - 3s/step - accuracy: 0.4983 - loss: 1.2942 - val_accuracy: 0.2611 - val_loss: 2.4898 - learning_rate: 2.0000e-05\n",
      "Epoch 11/20\n",
      "57/57 - 193s - 3s/step - accuracy: 0.5089 - loss: 1.2233 - val_accuracy: 0.2655 - val_loss: 2.4916 - learning_rate: 2.0000e-05\n",
      "Epoch 12/20\n",
      "57/57 - 190s - 3s/step - accuracy: 0.4994 - loss: 1.3043 - val_accuracy: 0.2389 - val_loss: 2.5871 - learning_rate: 4.0000e-06\n",
      "Epoch 13/20\n",
      "57/57 - 192s - 3s/step - accuracy: 0.5289 - loss: 1.2390 - val_accuracy: 0.2389 - val_loss: 2.6098 - learning_rate: 4.0000e-06\n",
      "Epoch 14/20\n",
      "57/57 - 199s - 3s/step - accuracy: 0.5200 - loss: 1.2004 - val_accuracy: 0.2301 - val_loss: 2.5821 - learning_rate: 4.0000e-06\n",
      "Epoch 15/20\n",
      "57/57 - 186s - 3s/step - accuracy: 0.5111 - loss: 1.2397 - val_accuracy: 0.2412 - val_loss: 2.6745 - learning_rate: 4.0000e-06\n",
      "Epoch 16/20\n",
      "57/57 - 190s - 3s/step - accuracy: 0.5244 - loss: 1.2161 - val_accuracy: 0.2699 - val_loss: 2.5333 - learning_rate: 4.0000e-06\n",
      "Epoch 17/20\n",
      "57/57 - 197s - 3s/step - accuracy: 0.5078 - loss: 1.2668 - val_accuracy: 0.2522 - val_loss: 2.5233 - learning_rate: 8.0000e-07\n",
      "Epoch 18/20\n",
      "57/57 - 196s - 3s/step - accuracy: 0.4989 - loss: 1.2796 - val_accuracy: 0.2478 - val_loss: 2.5235 - learning_rate: 8.0000e-07\n",
      "Epoch 19/20\n",
      "57/57 - 193s - 3s/step - accuracy: 0.5006 - loss: 1.2827 - val_accuracy: 0.2434 - val_loss: 2.5421 - learning_rate: 8.0000e-07\n",
      "Epoch 20/20\n",
      "57/57 - 193s - 3s/step - accuracy: 0.5017 - loss: 1.2457 - val_accuracy: 0.2478 - val_loss: 2.5403 - learning_rate: 8.0000e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=20,\n",
    "    validation_data=validation_dataset,\n",
    "    verbose=2,\n",
    "    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fdcf41ae744bd99825786f14bb77b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/*', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ee2dbe9aa54da6adfb1fa5087a9bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# File uploader for prediction\n",
    "uploader = widgets.FileUpload(accept=\"image/*\", multiple=True)\n",
    "display(uploader)\n",
    "\n",
    "# Output widget\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "# Function to process and predict each uploaded image\n",
    "def file_predict(filename, file, out):\n",
    "    \"\"\"Make predictions and display results.\"\"\"\n",
    "    # Load image and preprocess\n",
    "    image = tf.keras.utils.load_img(file, target_size=(150, 150))\n",
    "    image = tf.keras.utils.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0) / 255.0  # Normalize\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(image, verbose=0)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    # Map class indices to labels\n",
    "    class_names = train_dataset.class_indices\n",
    "    class_names = {v: k for k, v in class_names.items()}  # Invert mapping\n",
    "    predicted_label = class_names[predicted_class]\n",
    "\n",
    "    # Display results\n",
    "    with out:\n",
    "        print(f\"{filename} -> Predicted: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
